number of parameters: 123.59M
number of parameters: 123.59M
number of parameters: 123.59M
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
number of parameters: 123.59M
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
using fused AdamW: True
using fused AdamW: True
using fused AdamW: True
i8035:2153614:2153614 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
i8035:2153614:2153614 [0] NCCL INFO Bootstrap : Using ib0.0001:172.24.196.162<0>
i8035:2153614:2153614 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
i8035:2153614:2153614 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
i8035:2153614:2153614 [0] NCCL INFO NET/Plugin: Using internal network plugin.
i8035:2153614:2153614 [0] NCCL INFO cudaDriverVersion 12050
NCCL version 2.21.5+cuda12.4
i8035:2153616:2153616 [2] NCCL INFO cudaDriverVersion 12050
i8035:2153616:2153616 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
i8035:2153618:2153618 [3] NCCL INFO cudaDriverVersion 12050
i8035:2153618:2153618 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
i8035:2153615:2153615 [1] NCCL INFO cudaDriverVersion 12050
i8035:2153615:2153615 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
i8035:2153616:2153616 [2] NCCL INFO Bootstrap : Using ib0.0001:172.24.196.162<0>
i8035:2153616:2153616 [2] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
i8035:2153616:2153616 [2] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
i8035:2153616:2153616 [2] NCCL INFO NET/Plugin: Using internal network plugin.
i8035:2153618:2153618 [3] NCCL INFO Bootstrap : Using ib0.0001:172.24.196.162<0>
i8035:2153615:2153615 [1] NCCL INFO Bootstrap : Using ib0.0001:172.24.196.162<0>
i8035:2153618:2153618 [3] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
i8035:2153618:2153618 [3] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
i8035:2153618:2153618 [3] NCCL INFO NET/Plugin: Using internal network plugin.
i8035:2153615:2153615 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
i8035:2153615:2153615 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
i8035:2153615:2153615 [1] NCCL INFO NET/Plugin: Using internal network plugin.
i8035:2153614:2153662 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
i8035:2153614:2153662 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
i8035:2153615:2153665 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
i8035:2153614:2153662 [0] NCCL INFO NCCL_IB_HCA set to mlx5
i8035:2153615:2153665 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
i8035:2153615:2153665 [1] NCCL INFO NCCL_IB_HCA set to mlx5
i8035:2153618:2153664 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
i8035:2153618:2153664 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
i8035:2153618:2153664 [3] NCCL INFO NCCL_IB_HCA set to mlx5
i8035:2153616:2153663 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
i8035:2153616:2153663 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
i8035:2153616:2153663 [2] NCCL INFO NCCL_IB_HCA set to mlx5
i8035:2153614:2153662 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0.0001:172.24.196.162<0>
i8035:2153614:2153662 [0] NCCL INFO Using non-device net plugin version 0
i8035:2153614:2153662 [0] NCCL INFO Using network IB
i8035:2153615:2153665 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0.0001:172.24.196.162<0>
i8035:2153615:2153665 [1] NCCL INFO Using non-device net plugin version 0
i8035:2153615:2153665 [1] NCCL INFO Using network IB
i8035:2153618:2153664 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0.0001:172.24.196.162<0>
i8035:2153616:2153663 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0.0001:172.24.196.162<0>
i8035:2153618:2153664 [3] NCCL INFO Using non-device net plugin version 0
i8035:2153616:2153663 [2] NCCL INFO Using non-device net plugin version 0
i8035:2153618:2153664 [3] NCCL INFO Using network IB
i8035:2153616:2153663 [2] NCCL INFO Using network IB
i8035:2153614:2153662 [0] NCCL INFO ncclCommInitRank comm 0x8698d20 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId b000 commId 0xf219af1597212a4c - Init START
i8035:2153618:2153664 [3] NCCL INFO ncclCommInitRank comm 0x8ca9e20 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 90000 commId 0xf219af1597212a4c - Init START
i8035:2153615:2153665 [1] NCCL INFO ncclCommInitRank comm 0xa612660 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 11000 commId 0xf219af1597212a4c - Init START
i8035:2153616:2153663 [2] NCCL INFO ncclCommInitRank comm 0x88e8b40 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8b000 commId 0xf219af1597212a4c - Init START
i8035:2153615:2153665 [1] NCCL INFO NVLS multicast support is not available on dev 1
i8035:2153614:2153662 [0] NCCL INFO NVLS multicast support is not available on dev 0
i8035:2153618:2153664 [3] NCCL INFO NVLS multicast support is not available on dev 3
i8035:2153616:2153663 [2] NCCL INFO NVLS multicast support is not available on dev 2
i8035:2153615:2153665 [1] NCCL INFO comm 0xa612660 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
i8035:2153614:2153662 [0] NCCL INFO comm 0x8698d20 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
i8035:2153618:2153664 [3] NCCL INFO comm 0x8ca9e20 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
i8035:2153616:2153663 [2] NCCL INFO comm 0x88e8b40 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
i8035:2153614:2153662 [0] NCCL INFO Channel 00/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 01/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 02/24 :    0   1   2   3
i8035:2153615:2153665 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
i8035:2153614:2153662 [0] NCCL INFO Channel 03/24 :    0   1   2   3
i8035:2153615:2153665 [1] NCCL INFO P2P Chunksize set to 524288
i8035:2153614:2153662 [0] NCCL INFO Channel 04/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 05/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 06/24 :    0   1   2   3
i8035:2153618:2153664 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->2 [5] -1/-1/-1->3->2 [6] -1/-1/-1->3->2 [7] -1/-1/-1->3->2 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] -1/-1/-1->3->2 [11] -1/-1/-1->3->2 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->2 [17] -1/-1/-1->3->2 [18] -1/-1/-1->3->2 [19] -1/-1/-1->3->2 [20] -1/-1/-1->3->2 [21] -1/-1/-1->3->2 [22] -1/-1/-1->3->2 [23] -1/-1/-1->3->2
i8035:2153614:2153662 [0] NCCL INFO Channel 07/24 :    0   1   2   3
i8035:2153618:2153664 [3] NCCL INFO P2P Chunksize set to 524288
i8035:2153614:2153662 [0] NCCL INFO Channel 08/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 09/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 10/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 11/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 12/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 13/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 14/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 15/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 16/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 17/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 18/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 19/24 :    0   1   2   3
i8035:2153616:2153663 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
i8035:2153614:2153662 [0] NCCL INFO Channel 20/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 21/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Channel 22/24 :    0   1   2   3
i8035:2153616:2153663 [2] NCCL INFO P2P Chunksize set to 524288
i8035:2153614:2153662 [0] NCCL INFO Channel 23/24 :    0   1   2   3
i8035:2153614:2153662 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
i8035:2153614:2153662 [0] NCCL INFO P2P Chunksize set to 524288
i8035:2153618:2153664 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 01/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 04/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 05/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 07/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 08/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 10/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 11/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 13/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 14/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 16/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 17/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 19/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 20/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 22/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 23/0 : 3[3] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 08/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 09/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 11/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 14/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 17/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 19/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 20/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 21/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 23/0 : 1[1] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 15/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 16/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 17/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 19/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 21/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 22/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 23/0 : 2[2] -> 3[3] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 16/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 17/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 20/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 21/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 22/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Channel 23/0 : 0[0] -> 1[1] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Connected all rings
i8035:2153614:2153662 [0] NCCL INFO Connected all rings
i8035:2153618:2153664 [3] NCCL INFO Connected all rings
i8035:2153616:2153663 [2] NCCL INFO Connected all rings
i8035:2153618:2153664 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 16/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 18/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 19/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 21/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 22/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153615:2153665 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 15/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 08/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 16/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 18/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 12/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 13/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 20/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 21/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 16/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 22/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 18/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153618:2153664 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 19/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 20/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 22/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153616:2153663 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
i8035:2153614:2153662 [0] NCCL INFO Connected all trees
i8035:2153614:2153662 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
i8035:2153614:2153662 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
i8035:2153615:2153665 [1] NCCL INFO Connected all trees
i8035:2153615:2153665 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
i8035:2153615:2153665 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
i8035:2153616:2153663 [2] NCCL INFO Connected all trees
i8035:2153616:2153663 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
i8035:2153616:2153663 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
i8035:2153618:2153664 [3] NCCL INFO Connected all trees
i8035:2153618:2153664 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
i8035:2153618:2153664 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
i8035:2153615:2153665 [1] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
i8035:2153616:2153663 [2] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
i8035:2153616:2153663 [2] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
i8035:2153615:2153665 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
i8035:2153616:2153663 [2] NCCL INFO ncclCommInitRank comm 0x88e8b40 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8b000 commId 0xf219af1597212a4c - Init COMPLETE
i8035:2153615:2153665 [1] NCCL INFO ncclCommInitRank comm 0xa612660 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 11000 commId 0xf219af1597212a4c - Init COMPLETE
i8035:2153618:2153664 [3] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
i8035:2153614:2153662 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
i8035:2153618:2153664 [3] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
i8035:2153614:2153662 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
i8035:2153618:2153664 [3] NCCL INFO ncclCommInitRank comm 0x8ca9e20 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 90000 commId 0xf219af1597212a4c - Init COMPLETE
i8035:2153614:2153662 [0] NCCL INFO ncclCommInitRank comm 0x8698d20 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId b000 commId 0xf219af1597212a4c - Init COMPLETE
[debug] initial mask 124373760
[debug] initial canoical mask 124373760

=== ROUND 1/5 ===
[debug] Round 1 starting: 124373760/124373760 (100.00%) unmasked
[round] step 0: train 10.9886, val 10.9898
[round] iter 0: loss 10.9932, time 17925.7ms, mfu -100.0%
[round] iter 1: loss 10.0836, time 341.4ms, mfu -100.0%
[round] iter 2: loss 9.5032, time 425.6ms, mfu -100.0%
[round] iter 3: loss 8.9775, time 424.0ms, mfu -100.0%
[round] iter 4: loss 8.6610, time 425.2ms, mfu -100.0%
[round] iter 5: loss 8.2684, time 424.4ms, mfu 39.7%
[round] iter 6: loss 8.1304, time 427.2ms, mfu 39.6%
[round] iter 7: loss 7.9253, time 425.4ms, mfu 39.6%
[round] iter 8: loss 7.8842, time 426.9ms, mfu 39.6%
[round] iter 9: loss 7.6602, time 425.6ms, mfu 39.6%
[prune][debug] model has 75 params, mask has 75 entries
[prune][debug] params missing from mask (0): []…
[prune][debug] mask keys not in model (0): []…

[prune][debug] param transformer.wte.weight: 38633472/38633472 unmasked
[prune][debug] param transformer.wpe.weight: 786432/786432 unmasked
[prune][debug] param transformer.h.0.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.0.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.0.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.0.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.1.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.1.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.1.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.1.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.2.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.2.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.2.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.2.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.3.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.3.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.3.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.3.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.4.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.4.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.4.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.4.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.5.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.5.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.5.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.5.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.6.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.6.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.6.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.6.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.7.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.7.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.7.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.7.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.8.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.8.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.8.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.8.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.9.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.9.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.9.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.9.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.10.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.10.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.10.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.10.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.11.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.attn.c_attn.weight: 1769472/1769472 unmasked
[prune][debug] param transformer.h.11.attn.c_proj.weight: 589824/589824 unmasked
[prune][debug] param transformer.h.11.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.mlp.c_fc.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.h.11.mlp.c_proj.weight: 2359296/2359296 unmasked
[prune][debug] param transformer.ln_f.weight: 768/768 unmasked
[prune][debug] total unmasked vals = 124373760, k = 24874752 (20%)
[prune][debug] threshold = 2.747345e-03
[prune][debug] sample smallest: [5.820766091346741e-11, 8.731149137020111e-11, 1.4551915228366852e-10, 2.1100277081131935e-10, 2.764863893389702e-10, 2.764863893389702e-10, 8.658389560878277e-10, 9.476934792473912e-10, 1.0477378964424133e-09, 1.1132215149700642e-09]

[prune][debug] transformer.wte.weight: kept 34466809/38633472
[prune][debug] transformer.wpe.weight: kept 700360/786432
[prune][debug] transformer.h.0.ln_1.weight: kept 768/768
[prune][debug] transformer.h.0.attn.c_attn.weight: kept 1577649/1769472
[prune][debug] transformer.h.0.attn.c_proj.weight: kept 327980/589824
[prune][debug] transformer.h.0.ln_2.weight: kept 768/768
[prune][debug] transformer.h.0.mlp.c_fc.weight: kept 2103924/2359296
[prune][debug] transformer.h.0.mlp.c_proj.weight: kept 1362719/2359296
[prune][debug] transformer.h.1.ln_1.weight: kept 768/768
[prune][debug] transformer.h.1.attn.c_attn.weight: kept 1577085/1769472
[prune][debug] transformer.h.1.attn.c_proj.weight: kept 330852/589824
[prune][debug] transformer.h.1.ln_2.weight: kept 768/768
[prune][debug] transformer.h.1.mlp.c_fc.weight: kept 2102828/2359296
[prune][debug] transformer.h.1.mlp.c_proj.weight: kept 1346643/2359296
[prune][debug] transformer.h.2.ln_1.weight: kept 768/768
[prune][debug] transformer.h.2.attn.c_attn.weight: kept 1577565/1769472
[prune][debug] transformer.h.2.attn.c_proj.weight: kept 334154/589824
[prune][debug] transformer.h.2.ln_2.weight: kept 768/768
[prune][debug] transformer.h.2.mlp.c_fc.weight: kept 2102555/2359296
[prune][debug] transformer.h.2.mlp.c_proj.weight: kept 1344636/2359296
[prune][debug] transformer.h.3.ln_1.weight: kept 768/768
[prune][debug] transformer.h.3.attn.c_attn.weight: kept 1576904/1769472
[prune][debug] transformer.h.3.attn.c_proj.weight: kept 334797/589824
[prune][debug] transformer.h.3.ln_2.weight: kept 768/768
[prune][debug] transformer.h.3.mlp.c_fc.weight: kept 2103276/2359296
[prune][debug] transformer.h.3.mlp.c_proj.weight: kept 1343343/2359296
[prune][debug] transformer.h.4.ln_1.weight: kept 768/768
[prune][debug] transformer.h.4.attn.c_attn.weight: kept 1577581/1769472
[prune][debug] transformer.h.4.attn.c_proj.weight: kept 335253/589824
[prune][debug] transformer.h.4.ln_2.weight: kept 768/768
[prune][debug] transformer.h.4.mlp.c_fc.weight: kept 2103068/2359296
[prune][debug] transformer.h.4.mlp.c_proj.weight: kept 1344602/2359296
[prune][debug] transformer.h.5.ln_1.weight: kept 768/768
[prune][debug] transformer.h.5.attn.c_attn.weight: kept 1577121/1769472
[prune][debug] transformer.h.5.attn.c_proj.weight: kept 335613/589824
[prune][debug] transformer.h.5.ln_2.weight: kept 768/768
[prune][debug] transformer.h.5.mlp.c_fc.weight: kept 2102925/2359296
[prune][debug] transformer.h.5.mlp.c_proj.weight: kept 1342133/2359296
[prune][debug] transformer.h.6.ln_1.weight: kept 768/768
[prune][debug] transformer.h.6.attn.c_attn.weight: kept 1576881/1769472
[prune][debug] transformer.h.6.attn.c_proj.weight: kept 335491/589824
[prune][debug] transformer.h.6.ln_2.weight: kept 768/768
[prune][debug] transformer.h.6.mlp.c_fc.weight: kept 2103428/2359296
[prune][debug] transformer.h.6.mlp.c_proj.weight: kept 1342189/2359296
[prune][debug] transformer.h.7.ln_1.weight: kept 768/768
[prune][debug] transformer.h.7.attn.c_attn.weight: kept 1577357/1769472
[prune][debug] transformer.h.7.attn.c_proj.weight: kept 335484/589824
[prune][debug] transformer.h.7.ln_2.weight: kept 768/768
[prune][debug] transformer.h.7.mlp.c_fc.weight: kept 2103112/2359296
[prune][debug] transformer.h.7.mlp.c_proj.weight: kept 1342437/2359296
[prune][debug] transformer.h.8.ln_1.weight: kept 768/768
[prune][debug] transformer.h.8.attn.c_attn.weight: kept 1577064/1769472
[prune][debug] transformer.h.8.attn.c_proj.weight: kept 335040/589824
[prune][debug] transformer.h.8.ln_2.weight: kept 768/768
[prune][debug] transformer.h.8.mlp.c_fc.weight: kept 2103458/2359296
[prune][debug] transformer.h.8.mlp.c_proj.weight: kept 1338848/2359296
[prune][debug] transformer.h.9.ln_1.weight: kept 768/768
[prune][debug] transformer.h.9.attn.c_attn.weight: kept 1576484/1769472
[prune][debug] transformer.h.9.attn.c_proj.weight: kept 335608/589824
[prune][debug] transformer.h.9.ln_2.weight: kept 768/768
[prune][debug] transformer.h.9.mlp.c_fc.weight: kept 2103237/2359296
[prune][debug] transformer.h.9.mlp.c_proj.weight: kept 1340979/2359296
[prune][debug] transformer.h.10.ln_1.weight: kept 768/768
[prune][debug] transformer.h.10.attn.c_attn.weight: kept 1576620/1769472
[prune][debug] transformer.h.10.attn.c_proj.weight: kept 335720/589824
[prune][debug] transformer.h.10.ln_2.weight: kept 768/768
[prune][debug] transformer.h.10.mlp.c_fc.weight: kept 2103244/2359296
[prune][debug] transformer.h.10.mlp.c_proj.weight: kept 1343292/2359296
[prune][debug] transformer.h.11.ln_1.weight: kept 768/768
[prune][debug] transformer.h.11.attn.c_attn.weight: kept 1577697/1769472
[prune][debug] transformer.h.11.attn.c_proj.weight: kept 336256/589824
[prune][debug] transformer.h.11.ln_2.weight: kept 768/768
[prune][debug] transformer.h.11.mlp.c_fc.weight: kept 2103075/2359296
[prune][debug] transformer.h.11.mlp.c_proj.weight: kept 1344429/2359296
[prune][debug] transformer.ln_f.weight: kept 768/768
[prune][debug] remaining unmasked after prune: 99499004/124373760

[monitor] … → non-zero
[sparsity] 99499004/124373760 non-zero → 80.00%

=== ROUND 2/5 ===
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
using fused AdamW: True
using fused AdamW: True
[round] step 0: train 9.5438, val 9.5369
[round] iter 0: loss 9.5720, time 63377.7ms, mfu -100.0%
[round] iter 1: loss 9.2359, time 1273.6ms, mfu -100.0%
[round] iter 2: loss 9.9019, time 1310.9ms, mfu -100.0%
[round] iter 3: loss 8.6091, time 1406.9ms, mfu -100.0%
[round] iter 4: loss 8.4833, time 1239.0ms, mfu -100.0%
[round] iter 5: loss 8.0832, time 1263.1ms, mfu 13.3%
[round] iter 6: loss 8.0568, time 1338.3ms, mfu 13.3%
[round] iter 7: loss 7.8176, time 1230.1ms, mfu 13.3%
[round] iter 8: loss 7.6825, time 1204.3ms, mfu 13.4%
[round] iter 9: loss 7.8098, time 1341.1ms, mfu 13.3%
[prune][debug] model has 75 params, mask has 75 entries
[prune][debug] params missing from mask (0): []…
[prune][debug] mask keys not in model (0): []…

[prune][debug] param transformer.wte.weight: 34466809/38633472 unmasked
[prune][debug] param transformer.wpe.weight: 700360/786432 unmasked
[prune][debug] param transformer.h.0.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.attn.c_attn.weight: 1577649/1769472 unmasked
[prune][debug] param transformer.h.0.attn.c_proj.weight: 327980/589824 unmasked
[prune][debug] param transformer.h.0.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.mlp.c_fc.weight: 2103924/2359296 unmasked
[prune][debug] param transformer.h.0.mlp.c_proj.weight: 1362719/2359296 unmasked
[prune][debug] param transformer.h.1.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.attn.c_attn.weight: 1577085/1769472 unmasked
[prune][debug] param transformer.h.1.attn.c_proj.weight: 330852/589824 unmasked
[prune][debug] param transformer.h.1.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.mlp.c_fc.weight: 2102828/2359296 unmasked
[prune][debug] param transformer.h.1.mlp.c_proj.weight: 1346643/2359296 unmasked
[prune][debug] param transformer.h.2.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.attn.c_attn.weight: 1577565/1769472 unmasked
[prune][debug] param transformer.h.2.attn.c_proj.weight: 334154/589824 unmasked
[prune][debug] param transformer.h.2.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.mlp.c_fc.weight: 2102555/2359296 unmasked
[prune][debug] param transformer.h.2.mlp.c_proj.weight: 1344636/2359296 unmasked
[prune][debug] param transformer.h.3.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.attn.c_attn.weight: 1576904/1769472 unmasked
[prune][debug] param transformer.h.3.attn.c_proj.weight: 334797/589824 unmasked
[prune][debug] param transformer.h.3.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.mlp.c_fc.weight: 2103276/2359296 unmasked
[prune][debug] param transformer.h.3.mlp.c_proj.weight: 1343343/2359296 unmasked
[prune][debug] param transformer.h.4.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.attn.c_attn.weight: 1577581/1769472 unmasked
[prune][debug] param transformer.h.4.attn.c_proj.weight: 335253/589824 unmasked
[prune][debug] param transformer.h.4.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.mlp.c_fc.weight: 2103068/2359296 unmasked
[prune][debug] param transformer.h.4.mlp.c_proj.weight: 1344602/2359296 unmasked
[prune][debug] param transformer.h.5.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.attn.c_attn.weight: 1577121/1769472 unmasked
[prune][debug] param transformer.h.5.attn.c_proj.weight: 335613/589824 unmasked
[prune][debug] param transformer.h.5.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.mlp.c_fc.weight: 2102925/2359296 unmasked
[prune][debug] param transformer.h.5.mlp.c_proj.weight: 1342133/2359296 unmasked
[prune][debug] param transformer.h.6.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.attn.c_attn.weight: 1576881/1769472 unmasked
[prune][debug] param transformer.h.6.attn.c_proj.weight: 335491/589824 unmasked
[prune][debug] param transformer.h.6.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.mlp.c_fc.weight: 2103428/2359296 unmasked
[prune][debug] param transformer.h.6.mlp.c_proj.weight: 1342189/2359296 unmasked
[prune][debug] param transformer.h.7.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.attn.c_attn.weight: 1577357/1769472 unmasked
[prune][debug] param transformer.h.7.attn.c_proj.weight: 335484/589824 unmasked
[prune][debug] param transformer.h.7.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.mlp.c_fc.weight: 2103112/2359296 unmasked
[prune][debug] param transformer.h.7.mlp.c_proj.weight: 1342437/2359296 unmasked
[prune][debug] param transformer.h.8.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.attn.c_attn.weight: 1577064/1769472 unmasked
[prune][debug] param transformer.h.8.attn.c_proj.weight: 335040/589824 unmasked
[prune][debug] param transformer.h.8.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.mlp.c_fc.weight: 2103458/2359296 unmasked
[prune][debug] param transformer.h.8.mlp.c_proj.weight: 1338848/2359296 unmasked
[prune][debug] param transformer.h.9.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.attn.c_attn.weight: 1576484/1769472 unmasked
[prune][debug] param transformer.h.9.attn.c_proj.weight: 335608/589824 unmasked
[prune][debug] param transformer.h.9.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.mlp.c_fc.weight: 2103237/2359296 unmasked
[prune][debug] param transformer.h.9.mlp.c_proj.weight: 1340979/2359296 unmasked
[prune][debug] param transformer.h.10.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.attn.c_attn.weight: 1576620/1769472 unmasked
[prune][debug] param transformer.h.10.attn.c_proj.weight: 335720/589824 unmasked
[prune][debug] param transformer.h.10.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.mlp.c_fc.weight: 2103244/2359296 unmasked
[prune][debug] param transformer.h.10.mlp.c_proj.weight: 1343292/2359296 unmasked
[prune][debug] param transformer.h.11.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.attn.c_attn.weight: 1577697/1769472 unmasked
[prune][debug] param transformer.h.11.attn.c_proj.weight: 336256/589824 unmasked
[prune][debug] param transformer.h.11.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.mlp.c_fc.weight: 2103075/2359296 unmasked
[prune][debug] param transformer.h.11.mlp.c_proj.weight: 1344429/2359296 unmasked
[prune][debug] param transformer.ln_f.weight: 768/768 unmasked
[prune][debug] total unmasked vals = 99499005, k = 19899801 (20%)
[prune][debug] threshold = 4.798401e-03
[prune][debug] sample smallest: [4.3655745685100555e-10, 5.675246939063072e-10, 7.639755494892597e-10, 8.149072527885437e-10, 1.1204974725842476e-09, 1.1204974725842476e-09, 1.1932570487260818e-09, 2.255546860396862e-09, 2.6702764444053173e-09, 2.8994691092520952e-09]

[prune][debug] transformer.wte.weight: kept 31242806/34466809
[prune][debug] transformer.wpe.weight: kept 630624/700360
[prune][debug] transformer.h.0.ln_1.weight: kept 768/768
[prune][debug] transformer.h.0.attn.c_attn.weight: kept 1417525/1577649
[prune][debug] transformer.h.0.attn.c_proj.weight: kept 135661/327980
[prune][debug] transformer.h.0.ln_2.weight: kept 768/768
[prune][debug] transformer.h.0.mlp.c_fc.weight: kept 1875542/2103924
[prune][debug] transformer.h.0.mlp.c_proj.weight: kept 531315/1362719
[prune][debug] transformer.h.1.ln_1.weight: kept 768/768
[prune][debug] transformer.h.1.attn.c_attn.weight: kept 1401174/1577085
[prune][debug] transformer.h.1.attn.c_proj.weight: kept 142183/330852
[prune][debug] transformer.h.1.ln_2.weight: kept 768/768
[prune][debug] transformer.h.1.mlp.c_fc.weight: kept 1869188/2102828
[prune][debug] transformer.h.1.mlp.c_proj.weight: kept 553377/1346643
[prune][debug] transformer.h.2.ln_1.weight: kept 768/768
[prune][debug] transformer.h.2.attn.c_attn.weight: kept 1398344/1577565
[prune][debug] transformer.h.2.attn.c_proj.weight: kept 138000/334154
[prune][debug] transformer.h.2.ln_2.weight: kept 768/768
[prune][debug] transformer.h.2.mlp.c_fc.weight: kept 1871467/2102555
[prune][debug] transformer.h.2.mlp.c_proj.weight: kept 550704/1344636
[prune][debug] transformer.h.3.ln_1.weight: kept 768/768
[prune][debug] transformer.h.3.attn.c_attn.weight: kept 1403370/1576904
[prune][debug] transformer.h.3.attn.c_proj.weight: kept 135072/334797
[prune][debug] transformer.h.3.ln_2.weight: kept 768/768
[prune][debug] transformer.h.3.mlp.c_fc.weight: kept 1870496/2103276
[prune][debug] transformer.h.3.mlp.c_proj.weight: kept 545628/1343343
[prune][debug] transformer.h.4.ln_1.weight: kept 768/768
[prune][debug] transformer.h.4.attn.c_attn.weight: kept 1405413/1577581
[prune][debug] transformer.h.4.attn.c_proj.weight: kept 135889/335253
[prune][debug] transformer.h.4.ln_2.weight: kept 768/768
[prune][debug] transformer.h.4.mlp.c_fc.weight: kept 1870103/2103068
[prune][debug] transformer.h.4.mlp.c_proj.weight: kept 541368/1344602
[prune][debug] transformer.h.5.ln_1.weight: kept 768/768
[prune][debug] transformer.h.5.attn.c_attn.weight: kept 1407020/1577121
[prune][debug] transformer.h.5.attn.c_proj.weight: kept 135931/335613
[prune][debug] transformer.h.5.ln_2.weight: kept 768/768
[prune][debug] transformer.h.5.mlp.c_fc.weight: kept 1868181/2102925
[prune][debug] transformer.h.5.mlp.c_proj.weight: kept 541461/1342133
[prune][debug] transformer.h.6.ln_1.weight: kept 768/768
[prune][debug] transformer.h.6.attn.c_attn.weight: kept 1406251/1576881
[prune][debug] transformer.h.6.attn.c_proj.weight: kept 137909/335491
[prune][debug] transformer.h.6.ln_2.weight: kept 768/768
[prune][debug] transformer.h.6.mlp.c_fc.weight: kept 1870154/2103428
[prune][debug] transformer.h.6.mlp.c_proj.weight: kept 546938/1342189
[prune][debug] transformer.h.7.ln_1.weight: kept 768/768
[prune][debug] transformer.h.7.attn.c_attn.weight: kept 1407334/1577357
[prune][debug] transformer.h.7.attn.c_proj.weight: kept 138908/335484
[prune][debug] transformer.h.7.ln_2.weight: kept 768/768
[prune][debug] transformer.h.7.mlp.c_fc.weight: kept 1870903/2103112
[prune][debug] transformer.h.7.mlp.c_proj.weight: kept 551035/1342437
[prune][debug] transformer.h.8.ln_1.weight: kept 768/768
[prune][debug] transformer.h.8.attn.c_attn.weight: kept 1407126/1577064
[prune][debug] transformer.h.8.attn.c_proj.weight: kept 142691/335040
[prune][debug] transformer.h.8.ln_2.weight: kept 768/768
[prune][debug] transformer.h.8.mlp.c_fc.weight: kept 1872338/2103458
[prune][debug] transformer.h.8.mlp.c_proj.weight: kept 559761/1338848
[prune][debug] transformer.h.9.ln_1.weight: kept 768/768
[prune][debug] transformer.h.9.attn.c_attn.weight: kept 1406912/1576484
[prune][debug] transformer.h.9.attn.c_proj.weight: kept 145045/335608
[prune][debug] transformer.h.9.ln_2.weight: kept 768/768
[prune][debug] transformer.h.9.mlp.c_fc.weight: kept 1873721/2103237
[prune][debug] transformer.h.9.mlp.c_proj.weight: kept 572361/1340979
[prune][debug] transformer.h.10.ln_1.weight: kept 768/768
[prune][debug] transformer.h.10.attn.c_attn.weight: kept 1408566/1576620
[prune][debug] transformer.h.10.attn.c_proj.weight: kept 148827/335720
[prune][debug] transformer.h.10.ln_2.weight: kept 768/768
[prune][debug] transformer.h.10.mlp.c_fc.weight: kept 1875934/2103244
[prune][debug] transformer.h.10.mlp.c_proj.weight: kept 584963/1343292
[prune][debug] transformer.h.11.ln_1.weight: kept 768/768
[prune][debug] transformer.h.11.attn.c_attn.weight: kept 1410402/1577697
[prune][debug] transformer.h.11.attn.c_proj.weight: kept 151488/336256
[prune][debug] transformer.h.11.ln_2.weight: kept 768/768
[prune][debug] transformer.h.11.mlp.c_fc.weight: kept 1876994/2103075
[prune][debug] transformer.h.11.mlp.c_proj.weight: kept 595600/1344429
[prune][debug] transformer.ln_f.weight: kept 768/768
[prune][debug] remaining unmasked after prune: 79599203/99499005

[monitor] … → ZEROED OUT
[sparsity] 79599203/124373760 non-zero → 64.00%

=== ROUND 3/5 ===
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
using fused AdamW: True
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
[round] step 0: train 9.1513, val 9.1516
[round] iter 0: loss 9.2361, time 61273.1ms, mfu -100.0%
[round] iter 1: loss 8.7020, time 1399.3ms, mfu -100.0%
[round] iter 2: loss 8.2593, time 1321.6ms, mfu -100.0%
[round] iter 3: loss 8.0175, time 1240.9ms, mfu -100.0%
[round] iter 4: loss 7.8736, time 1179.5ms, mfu -100.0%
[round] iter 5: loss 7.6413, time 1360.8ms, mfu 12.4%
[round] iter 6: loss 7.4696, time 1278.7ms, mfu 12.4%
[round] iter 7: loss 7.8234, time 1295.0ms, mfu 12.5%
[round] iter 8: loss 7.5480, time 1327.4ms, mfu 12.5%
[round] iter 9: loss 7.5281, time 1357.7ms, mfu 12.5%
[prune][debug] model has 75 params, mask has 75 entries
[prune][debug] params missing from mask (0): []…
[prune][debug] mask keys not in model (0): []…

[prune][debug] param transformer.wte.weight: 31242806/38633472 unmasked
[prune][debug] param transformer.wpe.weight: 630624/786432 unmasked
[prune][debug] param transformer.h.0.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.attn.c_attn.weight: 1417525/1769472 unmasked
[prune][debug] param transformer.h.0.attn.c_proj.weight: 135661/589824 unmasked
[prune][debug] param transformer.h.0.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.mlp.c_fc.weight: 1875542/2359296 unmasked
[prune][debug] param transformer.h.0.mlp.c_proj.weight: 531315/2359296 unmasked
[prune][debug] param transformer.h.1.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.attn.c_attn.weight: 1401174/1769472 unmasked
[prune][debug] param transformer.h.1.attn.c_proj.weight: 142183/589824 unmasked
[prune][debug] param transformer.h.1.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.mlp.c_fc.weight: 1869188/2359296 unmasked
[prune][debug] param transformer.h.1.mlp.c_proj.weight: 553377/2359296 unmasked
[prune][debug] param transformer.h.2.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.attn.c_attn.weight: 1398344/1769472 unmasked
[prune][debug] param transformer.h.2.attn.c_proj.weight: 138000/589824 unmasked
[prune][debug] param transformer.h.2.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.mlp.c_fc.weight: 1871467/2359296 unmasked
[prune][debug] param transformer.h.2.mlp.c_proj.weight: 550704/2359296 unmasked
[prune][debug] param transformer.h.3.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.attn.c_attn.weight: 1403370/1769472 unmasked
[prune][debug] param transformer.h.3.attn.c_proj.weight: 135072/589824 unmasked
[prune][debug] param transformer.h.3.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.mlp.c_fc.weight: 1870496/2359296 unmasked
[prune][debug] param transformer.h.3.mlp.c_proj.weight: 545628/2359296 unmasked
[prune][debug] param transformer.h.4.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.attn.c_attn.weight: 1405413/1769472 unmasked
[prune][debug] param transformer.h.4.attn.c_proj.weight: 135889/589824 unmasked
[prune][debug] param transformer.h.4.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.mlp.c_fc.weight: 1870103/2359296 unmasked
[prune][debug] param transformer.h.4.mlp.c_proj.weight: 541368/2359296 unmasked
[prune][debug] param transformer.h.5.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.attn.c_attn.weight: 1407020/1769472 unmasked
[prune][debug] param transformer.h.5.attn.c_proj.weight: 135931/589824 unmasked
[prune][debug] param transformer.h.5.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.mlp.c_fc.weight: 1868181/2359296 unmasked
[prune][debug] param transformer.h.5.mlp.c_proj.weight: 541461/2359296 unmasked
[prune][debug] param transformer.h.6.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.attn.c_attn.weight: 1406251/1769472 unmasked
[prune][debug] param transformer.h.6.attn.c_proj.weight: 137909/589824 unmasked
[prune][debug] param transformer.h.6.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.mlp.c_fc.weight: 1870154/2359296 unmasked
[prune][debug] param transformer.h.6.mlp.c_proj.weight: 546938/2359296 unmasked
[prune][debug] param transformer.h.7.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.attn.c_attn.weight: 1407334/1769472 unmasked
[prune][debug] param transformer.h.7.attn.c_proj.weight: 138908/589824 unmasked
[prune][debug] param transformer.h.7.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.mlp.c_fc.weight: 1870903/2359296 unmasked
[prune][debug] param transformer.h.7.mlp.c_proj.weight: 551035/2359296 unmasked
[prune][debug] param transformer.h.8.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.attn.c_attn.weight: 1407126/1769472 unmasked
[prune][debug] param transformer.h.8.attn.c_proj.weight: 142691/589824 unmasked
[prune][debug] param transformer.h.8.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.mlp.c_fc.weight: 1872338/2359296 unmasked
[prune][debug] param transformer.h.8.mlp.c_proj.weight: 559761/2359296 unmasked
[prune][debug] param transformer.h.9.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.attn.c_attn.weight: 1406912/1769472 unmasked
[prune][debug] param transformer.h.9.attn.c_proj.weight: 145045/589824 unmasked
[prune][debug] param transformer.h.9.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.mlp.c_fc.weight: 1873721/2359296 unmasked
[prune][debug] param transformer.h.9.mlp.c_proj.weight: 572361/2359296 unmasked
[prune][debug] param transformer.h.10.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.attn.c_attn.weight: 1408566/1769472 unmasked
[prune][debug] param transformer.h.10.attn.c_proj.weight: 148827/589824 unmasked
[prune][debug] param transformer.h.10.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.mlp.c_fc.weight: 1875934/2359296 unmasked
[prune][debug] param transformer.h.10.mlp.c_proj.weight: 584963/2359296 unmasked
[prune][debug] param transformer.h.11.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.attn.c_attn.weight: 1410402/1769472 unmasked
[prune][debug] param transformer.h.11.attn.c_proj.weight: 151488/589824 unmasked
[prune][debug] param transformer.h.11.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.mlp.c_fc.weight: 1876994/2359296 unmasked
[prune][debug] param transformer.h.11.mlp.c_proj.weight: 595600/2359296 unmasked
[prune][debug] param transformer.ln_f.weight: 768/768 unmasked
[prune][debug] total unmasked vals = 79599203, k = 15919840 (20%)
[prune][debug] threshold = 7.950911e-03
[prune][debug] sample smallest: [9.560608305037022e-09, 1.83499651029706e-08, 2.2992026060819626e-08, 3.4458935260772705e-08, 3.6961864680051804e-08, 3.883906174451113e-08, 4.1894963942468166e-08, 4.216417437419295e-08, 4.222602001391351e-08, 5.5355485528707504e-08]

[prune][debug] transformer.wte.weight: kept 26824278/31242806
[prune][debug] transformer.wpe.weight: kept 536105/630624
[prune][debug] transformer.h.0.ln_1.weight: kept 768/768
[prune][debug] transformer.h.0.attn.c_attn.weight: kept 1217553/1417525
[prune][debug] transformer.h.0.attn.c_proj.weight: kept 41298/135661
[prune][debug] transformer.h.0.ln_2.weight: kept 768/768
[prune][debug] transformer.h.0.mlp.c_fc.weight: kept 1613803/1875542
[prune][debug] transformer.h.0.mlp.c_proj.weight: kept 178997/531315
[prune][debug] transformer.h.1.ln_1.weight: kept 768/768
[prune][debug] transformer.h.1.attn.c_attn.weight: kept 1207787/1401174
[prune][debug] transformer.h.1.attn.c_proj.weight: kept 37653/142183
[prune][debug] transformer.h.1.ln_2.weight: kept 768/768
[prune][debug] transformer.h.1.mlp.c_fc.weight: kept 1605251/1869188
[prune][debug] transformer.h.1.mlp.c_proj.weight: kept 170091/553377
[prune][debug] transformer.h.2.ln_1.weight: kept 768/768
[prune][debug] transformer.h.2.attn.c_attn.weight: kept 1206506/1398344
[prune][debug] transformer.h.2.attn.c_proj.weight: kept 40449/138000
[prune][debug] transformer.h.2.ln_2.weight: kept 768/768
[prune][debug] transformer.h.2.mlp.c_fc.weight: kept 1606065/1871467
[prune][debug] transformer.h.2.mlp.c_proj.weight: kept 166950/550704
[prune][debug] transformer.h.3.ln_1.weight: kept 768/768
[prune][debug] transformer.h.3.attn.c_attn.weight: kept 1209035/1403370
[prune][debug] transformer.h.3.attn.c_proj.weight: kept 41058/135072
[prune][debug] transformer.h.3.ln_2.weight: kept 768/768
[prune][debug] transformer.h.3.mlp.c_fc.weight: kept 1606612/1870496
[prune][debug] transformer.h.3.mlp.c_proj.weight: kept 165314/545628
[prune][debug] transformer.h.4.ln_1.weight: kept 768/768
[prune][debug] transformer.h.4.attn.c_attn.weight: kept 1209524/1405413
[prune][debug] transformer.h.4.attn.c_proj.weight: kept 40249/135889
[prune][debug] transformer.h.4.ln_2.weight: kept 768/768
[prune][debug] transformer.h.4.mlp.c_fc.weight: kept 1610525/1870103
[prune][debug] transformer.h.4.mlp.c_proj.weight: kept 163470/541368
[prune][debug] transformer.h.5.ln_1.weight: kept 768/768
[prune][debug] transformer.h.5.attn.c_attn.weight: kept 1211070/1407020
[prune][debug] transformer.h.5.attn.c_proj.weight: kept 40095/135931
[prune][debug] transformer.h.5.ln_2.weight: kept 768/768
[prune][debug] transformer.h.5.mlp.c_fc.weight: kept 1612102/1868181
[prune][debug] transformer.h.5.mlp.c_proj.weight: kept 162736/541461
[prune][debug] transformer.h.6.ln_1.weight: kept 768/768
[prune][debug] transformer.h.6.attn.c_attn.weight: kept 1210660/1406251
[prune][debug] transformer.h.6.attn.c_proj.weight: kept 39739/137909
[prune][debug] transformer.h.6.ln_2.weight: kept 768/768
[prune][debug] transformer.h.6.mlp.c_fc.weight: kept 1614908/1870154
[prune][debug] transformer.h.6.mlp.c_proj.weight: kept 160144/546938
[prune][debug] transformer.h.7.ln_1.weight: kept 768/768
[prune][debug] transformer.h.7.attn.c_attn.weight: kept 1208388/1407334
[prune][debug] transformer.h.7.attn.c_proj.weight: kept 38677/138908
[prune][debug] transformer.h.7.ln_2.weight: kept 768/768
[prune][debug] transformer.h.7.mlp.c_fc.weight: kept 1615581/1870903
[prune][debug] transformer.h.7.mlp.c_proj.weight: kept 157010/551035
[prune][debug] transformer.h.8.ln_1.weight: kept 768/768
[prune][debug] transformer.h.8.attn.c_attn.weight: kept 1210335/1407126
[prune][debug] transformer.h.8.attn.c_proj.weight: kept 38520/142691
[prune][debug] transformer.h.8.ln_2.weight: kept 768/768
[prune][debug] transformer.h.8.mlp.c_fc.weight: kept 1615449/1872338
[prune][debug] transformer.h.8.mlp.c_proj.weight: kept 154262/559761
[prune][debug] transformer.h.9.ln_1.weight: kept 768/768
[prune][debug] transformer.h.9.attn.c_attn.weight: kept 1211622/1406912
[prune][debug] transformer.h.9.attn.c_proj.weight: kept 38650/145045
[prune][debug] transformer.h.9.ln_2.weight: kept 768/768
[prune][debug] transformer.h.9.mlp.c_fc.weight: kept 1617754/1873721
[prune][debug] transformer.h.9.mlp.c_proj.weight: kept 152607/572361
[prune][debug] transformer.h.10.ln_1.weight: kept 768/768
[prune][debug] transformer.h.10.attn.c_attn.weight: kept 1212962/1408566
[prune][debug] transformer.h.10.attn.c_proj.weight: kept 38755/148827
[prune][debug] transformer.h.10.ln_2.weight: kept 768/768
[prune][debug] transformer.h.10.mlp.c_fc.weight: kept 1619608/1875934
[prune][debug] transformer.h.10.mlp.c_proj.weight: kept 152572/584963
[prune][debug] transformer.h.11.ln_1.weight: kept 768/768
[prune][debug] transformer.h.11.attn.c_attn.weight: kept 1215768/1410402
[prune][debug] transformer.h.11.attn.c_proj.weight: kept 39052/151488
[prune][debug] transformer.h.11.ln_2.weight: kept 768/768
[prune][debug] transformer.h.11.mlp.c_fc.weight: kept 1619766/1876994
[prune][debug] transformer.h.11.mlp.c_proj.weight: kept 152796/595600
[prune][debug] transformer.ln_f.weight: kept 768/768
[prune][debug] remaining unmasked after prune: 63679361/79599203

[monitor] … → ZEROED OUT
[sparsity] 63679361/124373760 non-zero → 51.20%

=== ROUND 4/5 ===
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
using fused AdamW: True
using fused AdamW: True
[round] step 0: train 9.4022, val 9.4060
[round] iter 0: loss 9.4184, time 61484.2ms, mfu -100.0%
[round] iter 1: loss 8.5338, time 1431.6ms, mfu -100.0%
[round] iter 2: loss 8.1336, time 1235.4ms, mfu -100.0%
[round] iter 3: loss 7.9856, time 1296.4ms, mfu -100.0%
[round] iter 4: loss 7.6504, time 1426.5ms, mfu -100.0%
[round] iter 5: loss 7.7161, time 1334.5ms, mfu 12.6%
[round] iter 6: loss 7.4372, time 1257.1ms, mfu 12.7%
[round] iter 7: loss 7.4469, time 1296.6ms, mfu 12.7%
[round] iter 8: loss 7.5835, time 1318.4ms, mfu 12.7%
[round] iter 9: loss 7.5869, time 1346.1ms, mfu 12.7%
[prune][debug] model has 75 params, mask has 75 entries
[prune][debug] params missing from mask (0): []…
[prune][debug] mask keys not in model (0): []…

[prune][debug] param transformer.wte.weight: 26824278/38633472 unmasked
[prune][debug] param transformer.wpe.weight: 536105/786432 unmasked
[prune][debug] param transformer.h.0.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.attn.c_attn.weight: 1217553/1769472 unmasked
[prune][debug] param transformer.h.0.attn.c_proj.weight: 41298/589824 unmasked
[prune][debug] param transformer.h.0.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.mlp.c_fc.weight: 1613803/2359296 unmasked
[prune][debug] param transformer.h.0.mlp.c_proj.weight: 178997/2359296 unmasked
[prune][debug] param transformer.h.1.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.attn.c_attn.weight: 1207787/1769472 unmasked
[prune][debug] param transformer.h.1.attn.c_proj.weight: 37653/589824 unmasked
[prune][debug] param transformer.h.1.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.mlp.c_fc.weight: 1605251/2359296 unmasked
[prune][debug] param transformer.h.1.mlp.c_proj.weight: 170091/2359296 unmasked
[prune][debug] param transformer.h.2.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.attn.c_attn.weight: 1206506/1769472 unmasked
[prune][debug] param transformer.h.2.attn.c_proj.weight: 40449/589824 unmasked
[prune][debug] param transformer.h.2.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.mlp.c_fc.weight: 1606065/2359296 unmasked
[prune][debug] param transformer.h.2.mlp.c_proj.weight: 166950/2359296 unmasked
[prune][debug] param transformer.h.3.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.attn.c_attn.weight: 1209035/1769472 unmasked
[prune][debug] param transformer.h.3.attn.c_proj.weight: 41058/589824 unmasked
[prune][debug] param transformer.h.3.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.mlp.c_fc.weight: 1606612/2359296 unmasked
[prune][debug] param transformer.h.3.mlp.c_proj.weight: 165314/2359296 unmasked
[prune][debug] param transformer.h.4.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.attn.c_attn.weight: 1209524/1769472 unmasked
[prune][debug] param transformer.h.4.attn.c_proj.weight: 40249/589824 unmasked
[prune][debug] param transformer.h.4.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.mlp.c_fc.weight: 1610525/2359296 unmasked
[prune][debug] param transformer.h.4.mlp.c_proj.weight: 163470/2359296 unmasked
[prune][debug] param transformer.h.5.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.attn.c_attn.weight: 1211070/1769472 unmasked
[prune][debug] param transformer.h.5.attn.c_proj.weight: 40095/589824 unmasked
[prune][debug] param transformer.h.5.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.mlp.c_fc.weight: 1612102/2359296 unmasked
[prune][debug] param transformer.h.5.mlp.c_proj.weight: 162736/2359296 unmasked
[prune][debug] param transformer.h.6.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.attn.c_attn.weight: 1210660/1769472 unmasked
[prune][debug] param transformer.h.6.attn.c_proj.weight: 39739/589824 unmasked
[prune][debug] param transformer.h.6.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.mlp.c_fc.weight: 1614908/2359296 unmasked
[prune][debug] param transformer.h.6.mlp.c_proj.weight: 160144/2359296 unmasked
[prune][debug] param transformer.h.7.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.attn.c_attn.weight: 1208388/1769472 unmasked
[prune][debug] param transformer.h.7.attn.c_proj.weight: 38677/589824 unmasked
[prune][debug] param transformer.h.7.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.mlp.c_fc.weight: 1615581/2359296 unmasked
[prune][debug] param transformer.h.7.mlp.c_proj.weight: 157010/2359296 unmasked
[prune][debug] param transformer.h.8.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.attn.c_attn.weight: 1210335/1769472 unmasked
[prune][debug] param transformer.h.8.attn.c_proj.weight: 38520/589824 unmasked
[prune][debug] param transformer.h.8.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.mlp.c_fc.weight: 1615449/2359296 unmasked
[prune][debug] param transformer.h.8.mlp.c_proj.weight: 154262/2359296 unmasked
[prune][debug] param transformer.h.9.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.attn.c_attn.weight: 1211622/1769472 unmasked
[prune][debug] param transformer.h.9.attn.c_proj.weight: 38650/589824 unmasked
[prune][debug] param transformer.h.9.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.mlp.c_fc.weight: 1617754/2359296 unmasked
[prune][debug] param transformer.h.9.mlp.c_proj.weight: 152607/2359296 unmasked
[prune][debug] param transformer.h.10.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.attn.c_attn.weight: 1212962/1769472 unmasked
[prune][debug] param transformer.h.10.attn.c_proj.weight: 38755/589824 unmasked
[prune][debug] param transformer.h.10.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.mlp.c_fc.weight: 1619608/2359296 unmasked
[prune][debug] param transformer.h.10.mlp.c_proj.weight: 152572/2359296 unmasked
[prune][debug] param transformer.h.11.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.attn.c_attn.weight: 1215768/1769472 unmasked
[prune][debug] param transformer.h.11.attn.c_proj.weight: 39052/589824 unmasked
[prune][debug] param transformer.h.11.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.mlp.c_fc.weight: 1619766/2359296 unmasked
[prune][debug] param transformer.h.11.mlp.c_proj.weight: 152796/2359296 unmasked
[prune][debug] param transformer.ln_f.weight: 768/768 unmasked
[prune][debug] total unmasked vals = 63679361, k = 12735872 (20%)
[prune][debug] threshold = 1.138994e-02
[prune][debug] sample smallest: [2.1740561351180077e-08, 1.903099473565817e-07, 2.511951606720686e-07, 4.260509740561247e-07, 5.665933713316917e-07, 8.708448149263859e-07, 9.451905498281121e-07, 1.0317307896912098e-06, 1.4135948731563985e-06, 1.4398247003555298e-06]

[prune][debug] transformer.wte.weight: kept 22179938/26824278
[prune][debug] transformer.wpe.weight: kept 438923/536105
[prune][debug] transformer.h.0.ln_1.weight: kept 768/768
[prune][debug] transformer.h.0.attn.c_attn.weight: kept 1000702/1217553
[prune][debug] transformer.h.0.attn.c_proj.weight: kept 5110/41298
[prune][debug] transformer.h.0.ln_2.weight: kept 768/768
[prune][debug] transformer.h.0.mlp.c_fc.weight: kept 1325111/1613803
[prune][debug] transformer.h.0.mlp.c_proj.weight: kept 32208/178997
[prune][debug] transformer.h.1.ln_1.weight: kept 768/768
[prune][debug] transformer.h.1.attn.c_attn.weight: kept 999127/1207787
[prune][debug] transformer.h.1.attn.c_proj.weight: kept 6373/37653
[prune][debug] transformer.h.1.ln_2.weight: kept 768/768
[prune][debug] transformer.h.1.mlp.c_fc.weight: kept 1323511/1605251
[prune][debug] transformer.h.1.mlp.c_proj.weight: kept 27166/170091
[prune][debug] transformer.h.2.ln_1.weight: kept 768/768
[prune][debug] transformer.h.2.attn.c_attn.weight: kept 992141/1206506
[prune][debug] transformer.h.2.attn.c_proj.weight: kept 6228/40449
[prune][debug] transformer.h.2.ln_2.weight: kept 768/768
[prune][debug] transformer.h.2.mlp.c_fc.weight: kept 1325712/1606065
[prune][debug] transformer.h.2.mlp.c_proj.weight: kept 26459/166950
[prune][debug] transformer.h.3.ln_1.weight: kept 768/768
[prune][debug] transformer.h.3.attn.c_attn.weight: kept 990794/1209035
[prune][debug] transformer.h.3.attn.c_proj.weight: kept 6430/41058
[prune][debug] transformer.h.3.ln_2.weight: kept 768/768
[prune][debug] transformer.h.3.mlp.c_fc.weight: kept 1323600/1606612
[prune][debug] transformer.h.3.mlp.c_proj.weight: kept 26428/165314
[prune][debug] transformer.h.4.ln_1.weight: kept 768/768
[prune][debug] transformer.h.4.attn.c_attn.weight: kept 991290/1209524
[prune][debug] transformer.h.4.attn.c_proj.weight: kept 6310/40249
[prune][debug] transformer.h.4.ln_2.weight: kept 768/768
[prune][debug] transformer.h.4.mlp.c_fc.weight: kept 1325398/1610525
[prune][debug] transformer.h.4.mlp.c_proj.weight: kept 26409/163470
[prune][debug] transformer.h.5.ln_1.weight: kept 768/768
[prune][debug] transformer.h.5.attn.c_attn.weight: kept 991619/1211070
[prune][debug] transformer.h.5.attn.c_proj.weight: kept 6378/40095
[prune][debug] transformer.h.5.ln_2.weight: kept 768/768
[prune][debug] transformer.h.5.mlp.c_fc.weight: kept 1326734/1612102
[prune][debug] transformer.h.5.mlp.c_proj.weight: kept 26944/162736
[prune][debug] transformer.h.6.ln_1.weight: kept 768/768
[prune][debug] transformer.h.6.attn.c_attn.weight: kept 995028/1210660
[prune][debug] transformer.h.6.attn.c_proj.weight: kept 6649/39739
[prune][debug] transformer.h.6.ln_2.weight: kept 768/768
[prune][debug] transformer.h.6.mlp.c_fc.weight: kept 1328990/1614908
[prune][debug] transformer.h.6.mlp.c_proj.weight: kept 27027/160144
[prune][debug] transformer.h.7.ln_1.weight: kept 768/768
[prune][debug] transformer.h.7.attn.c_attn.weight: kept 995723/1208388
[prune][debug] transformer.h.7.attn.c_proj.weight: kept 7340/38677
[prune][debug] transformer.h.7.ln_2.weight: kept 768/768
[prune][debug] transformer.h.7.mlp.c_fc.weight: kept 1329513/1615581
[prune][debug] transformer.h.7.mlp.c_proj.weight: kept 27943/157010
[prune][debug] transformer.h.8.ln_1.weight: kept 768/768
[prune][debug] transformer.h.8.attn.c_attn.weight: kept 997713/1210335
[prune][debug] transformer.h.8.attn.c_proj.weight: kept 7203/38520
[prune][debug] transformer.h.8.ln_2.weight: kept 768/768
[prune][debug] transformer.h.8.mlp.c_fc.weight: kept 1329522/1615449
[prune][debug] transformer.h.8.mlp.c_proj.weight: kept 28852/154262
[prune][debug] transformer.h.9.ln_1.weight: kept 768/768
[prune][debug] transformer.h.9.attn.c_attn.weight: kept 998397/1211622
[prune][debug] transformer.h.9.attn.c_proj.weight: kept 7430/38650
[prune][debug] transformer.h.9.ln_2.weight: kept 768/768
[prune][debug] transformer.h.9.mlp.c_fc.weight: kept 1330909/1617754
[prune][debug] transformer.h.9.mlp.c_proj.weight: kept 29442/152607
[prune][debug] transformer.h.10.ln_1.weight: kept 768/768
[prune][debug] transformer.h.10.attn.c_attn.weight: kept 999007/1212962
[prune][debug] transformer.h.10.attn.c_proj.weight: kept 7452/38755
[prune][debug] transformer.h.10.ln_2.weight: kept 768/768
[prune][debug] transformer.h.10.mlp.c_fc.weight: kept 1331749/1619608
[prune][debug] transformer.h.10.mlp.c_proj.weight: kept 30196/152572
[prune][debug] transformer.h.11.ln_1.weight: kept 768/768
[prune][debug] transformer.h.11.attn.c_attn.weight: kept 1001304/1215768
[prune][debug] transformer.h.11.attn.c_proj.weight: kept 7812/39052
[prune][debug] transformer.h.11.ln_2.weight: kept 768/768
[prune][debug] transformer.h.11.mlp.c_fc.weight: kept 1331299/1619766
[prune][debug] transformer.h.11.mlp.c_proj.weight: kept 30746/152796
[prune][debug] transformer.ln_f.weight: kept 768/768
[prune][debug] remaining unmasked after prune: 50943489/63679361

[monitor] … → ZEROED OUT
[sparsity] 50943489/124373760 non-zero → 40.96%

=== ROUND 5/5 ===
num decayed parameter tensors: 50, with 124,354,560 parametersnum decayed parameter tensors: 50, with 124,354,560 parameters

num non-decayed parameter tensors: 25, with 19,200 parametersnum non-decayed parameter tensors: 25, with 19,200 parameters

num decayed parameter tensors: 50, with 124,354,560 parameters
using fused AdamW: Truenum non-decayed parameter tensors: 25, with 19,200 parametersusing fused AdamW: True


num decayed parameter tensors: 50, with 124,354,560 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
using fused AdamW: True
[round] step 0: train 8.8295, val 8.8356
[round] iter 0: loss 8.8756, time 61028.0ms, mfu -100.0%
[round] iter 1: loss 8.4344, time 1318.2ms, mfu -100.0%
[round] iter 2: loss 7.9776, time 1411.0ms, mfu -100.0%
[round] iter 3: loss 7.7081, time 1323.9ms, mfu -100.0%
[round] iter 4: loss 7.6331, time 1530.3ms, mfu -100.0%
[round] iter 5: loss 7.6609, time 1315.4ms, mfu 12.8%
[round] iter 6: loss 7.4187, time 1209.5ms, mfu 12.9%
[round] iter 7: loss 7.3767, time 1333.0ms, mfu 12.9%
[round] iter 8: loss 7.4368, time 1268.1ms, mfu 12.9%
[round] iter 9: loss 7.5249, time 1226.5ms, mfu 13.0%
[prune][debug] model has 75 params, mask has 75 entries
[prune][debug] params missing from mask (0): []…
[prune][debug] mask keys not in model (0): []…

[prune][debug] param transformer.wte.weight: 22179938/38633472 unmasked
[prune][debug] param transformer.wpe.weight: 438923/786432 unmasked
[prune][debug] param transformer.h.0.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.attn.c_attn.weight: 1000702/1769472 unmasked
[prune][debug] param transformer.h.0.attn.c_proj.weight: 5110/589824 unmasked
[prune][debug] param transformer.h.0.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.0.mlp.c_fc.weight: 1325111/2359296 unmasked
[prune][debug] param transformer.h.0.mlp.c_proj.weight: 32208/2359296 unmasked
[prune][debug] param transformer.h.1.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.attn.c_attn.weight: 999127/1769472 unmasked
[prune][debug] param transformer.h.1.attn.c_proj.weight: 6373/589824 unmasked
[prune][debug] param transformer.h.1.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.1.mlp.c_fc.weight: 1323511/2359296 unmasked
[prune][debug] param transformer.h.1.mlp.c_proj.weight: 27166/2359296 unmasked
[prune][debug] param transformer.h.2.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.attn.c_attn.weight: 992141/1769472 unmasked
[prune][debug] param transformer.h.2.attn.c_proj.weight: 6228/589824 unmasked
[prune][debug] param transformer.h.2.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.2.mlp.c_fc.weight: 1325712/2359296 unmasked
[prune][debug] param transformer.h.2.mlp.c_proj.weight: 26459/2359296 unmasked
[prune][debug] param transformer.h.3.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.attn.c_attn.weight: 990794/1769472 unmasked
[prune][debug] param transformer.h.3.attn.c_proj.weight: 6430/589824 unmasked
[prune][debug] param transformer.h.3.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.3.mlp.c_fc.weight: 1323600/2359296 unmasked
[prune][debug] param transformer.h.3.mlp.c_proj.weight: 26428/2359296 unmasked
[prune][debug] param transformer.h.4.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.attn.c_attn.weight: 991290/1769472 unmasked
[prune][debug] param transformer.h.4.attn.c_proj.weight: 6310/589824 unmasked
[prune][debug] param transformer.h.4.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.4.mlp.c_fc.weight: 1325398/2359296 unmasked
[prune][debug] param transformer.h.4.mlp.c_proj.weight: 26409/2359296 unmasked
[prune][debug] param transformer.h.5.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.attn.c_attn.weight: 991619/1769472 unmasked
[prune][debug] param transformer.h.5.attn.c_proj.weight: 6378/589824 unmasked
[prune][debug] param transformer.h.5.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.5.mlp.c_fc.weight: 1326734/2359296 unmasked
[prune][debug] param transformer.h.5.mlp.c_proj.weight: 26944/2359296 unmasked
[prune][debug] param transformer.h.6.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.attn.c_attn.weight: 995028/1769472 unmasked
[prune][debug] param transformer.h.6.attn.c_proj.weight: 6649/589824 unmasked
[prune][debug] param transformer.h.6.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.6.mlp.c_fc.weight: 1328990/2359296 unmasked
[prune][debug] param transformer.h.6.mlp.c_proj.weight: 27027/2359296 unmasked
[prune][debug] param transformer.h.7.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.attn.c_attn.weight: 995723/1769472 unmasked
[prune][debug] param transformer.h.7.attn.c_proj.weight: 7340/589824 unmasked
[prune][debug] param transformer.h.7.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.7.mlp.c_fc.weight: 1329513/2359296 unmasked
[prune][debug] param transformer.h.7.mlp.c_proj.weight: 27943/2359296 unmasked
[prune][debug] param transformer.h.8.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.attn.c_attn.weight: 997713/1769472 unmasked
[prune][debug] param transformer.h.8.attn.c_proj.weight: 7203/589824 unmasked
[prune][debug] param transformer.h.8.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.8.mlp.c_fc.weight: 1329522/2359296 unmasked
[prune][debug] param transformer.h.8.mlp.c_proj.weight: 28852/2359296 unmasked
[prune][debug] param transformer.h.9.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.attn.c_attn.weight: 998397/1769472 unmasked
[prune][debug] param transformer.h.9.attn.c_proj.weight: 7430/589824 unmasked
[prune][debug] param transformer.h.9.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.9.mlp.c_fc.weight: 1330909/2359296 unmasked
[prune][debug] param transformer.h.9.mlp.c_proj.weight: 29442/2359296 unmasked
[prune][debug] param transformer.h.10.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.attn.c_attn.weight: 999007/1769472 unmasked
[prune][debug] param transformer.h.10.attn.c_proj.weight: 7452/589824 unmasked
[prune][debug] param transformer.h.10.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.10.mlp.c_fc.weight: 1331749/2359296 unmasked
[prune][debug] param transformer.h.10.mlp.c_proj.weight: 30196/2359296 unmasked
[prune][debug] param transformer.h.11.ln_1.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.attn.c_attn.weight: 1001304/1769472 unmasked
[prune][debug] param transformer.h.11.attn.c_proj.weight: 7812/589824 unmasked
[prune][debug] param transformer.h.11.ln_2.weight: 768/768 unmasked
[prune][debug] param transformer.h.11.mlp.c_fc.weight: 1331299/2359296 unmasked
[prune][debug] param transformer.h.11.mlp.c_proj.weight: 30746/2359296 unmasked
[prune][debug] param transformer.ln_f.weight: 768/768 unmasked
[prune][debug] total unmasked vals = 50943489, k = 10188697 (20%)
[prune][debug] threshold = 1.482224e-02
[prune][debug] sample smallest: [0.00010708410991355777, 0.0006360143888741732, 0.0008455362403765321, 0.0008664614288136363, 0.0008737904136069119, 0.0008842973620630801, 0.0010097690392285585, 0.001025061123073101, 0.001100338064134121, 0.0011959100374951959]

[prune][debug] transformer.wte.weight: kept 17914224/22179938
[prune][debug] transformer.wpe.weight: kept 348596/438923
[prune][debug] transformer.h.0.ln_1.weight: kept 768/768
[prune][debug] transformer.h.0.attn.c_attn.weight: kept 807001/1000702
[prune][debug] transformer.h.0.attn.c_proj.weight: kept 361/5110
[prune][debug] transformer.h.0.ln_2.weight: kept 768/768
[prune][debug] transformer.h.0.mlp.c_fc.weight: kept 1074352/1325111
[prune][debug] transformer.h.0.mlp.c_proj.weight: kept 2640/32208
[prune][debug] transformer.h.1.ln_1.weight: kept 768/768
[prune][debug] transformer.h.1.attn.c_attn.weight: kept 804203/999127
[prune][debug] transformer.h.1.attn.c_proj.weight: kept 335/6373
[prune][debug] transformer.h.1.ln_2.weight: kept 768/768
[prune][debug] transformer.h.1.mlp.c_fc.weight: kept 1070331/1323511
[prune][debug] transformer.h.1.mlp.c_proj.weight: kept 2266/27166
[prune][debug] transformer.h.2.ln_1.weight: kept 768/768
[prune][debug] transformer.h.2.attn.c_attn.weight: kept 803149/992141
[prune][debug] transformer.h.2.attn.c_proj.weight: kept 375/6228
[prune][debug] transformer.h.2.ln_2.weight: kept 768/768
[prune][debug] transformer.h.2.mlp.c_fc.weight: kept 1069592/1325712
[prune][debug] transformer.h.2.mlp.c_proj.weight: kept 2186/26459
[prune][debug] transformer.h.3.ln_1.weight: kept 768/768
[prune][debug] transformer.h.3.attn.c_attn.weight: kept 802701/990794
[prune][debug] transformer.h.3.attn.c_proj.weight: kept 429/6430
[prune][debug] transformer.h.3.ln_2.weight: kept 768/768
[prune][debug] transformer.h.3.mlp.c_fc.weight: kept 1067098/1323600
[prune][debug] transformer.h.3.mlp.c_proj.weight: kept 2205/26428
[prune][debug] transformer.h.4.ln_1.weight: kept 768/768
[prune][debug] transformer.h.4.attn.c_attn.weight: kept 800582/991290
[prune][debug] transformer.h.4.attn.c_proj.weight: kept 477/6310
[prune][debug] transformer.h.4.ln_2.weight: kept 768/768
[prune][debug] transformer.h.4.mlp.c_fc.weight: kept 1067197/1325398
[prune][debug] transformer.h.4.mlp.c_proj.weight: kept 2235/26409
[prune][debug] transformer.h.5.ln_1.weight: kept 768/768
[prune][debug] transformer.h.5.attn.c_attn.weight: kept 801551/991619
[prune][debug] transformer.h.5.attn.c_proj.weight: kept 536/6378
[prune][debug] transformer.h.5.ln_2.weight: kept 768/768
[prune][debug] transformer.h.5.mlp.c_fc.weight: kept 1066761/1326734
[prune][debug] transformer.h.5.mlp.c_proj.weight: kept 2090/26944
[prune][debug] transformer.h.6.ln_1.weight: kept 768/768
[prune][debug] transformer.h.6.attn.c_attn.weight: kept 801699/995028
[prune][debug] transformer.h.6.attn.c_proj.weight: kept 496/6649
[prune][debug] transformer.h.6.ln_2.weight: kept 768/768
[prune][debug] transformer.h.6.mlp.c_fc.weight: kept 1068204/1328990
[prune][debug] transformer.h.6.mlp.c_proj.weight: kept 2223/27027
[prune][debug] transformer.h.7.ln_1.weight: kept 768/768
[prune][debug] transformer.h.7.attn.c_attn.weight: kept 801930/995723
[prune][debug] transformer.h.7.attn.c_proj.weight: kept 555/7340
[prune][debug] transformer.h.7.ln_2.weight: kept 768/768
[prune][debug] transformer.h.7.mlp.c_fc.weight: kept 1064534/1329513
[prune][debug] transformer.h.7.mlp.c_proj.weight: kept 2284/27943
[prune][debug] transformer.h.8.ln_1.weight: kept 768/768
[prune][debug] transformer.h.8.attn.c_attn.weight: kept 804079/997713
[prune][debug] transformer.h.8.attn.c_proj.weight: kept 542/7203
[prune][debug] transformer.h.8.ln_2.weight: kept 768/768
[prune][debug] transformer.h.8.mlp.c_fc.weight: kept 1063474/1329522
[prune][debug] transformer.h.8.mlp.c_proj.weight: kept 2435/28852
[prune][debug] transformer.h.9.ln_1.weight: kept 768/768
[prune][debug] transformer.h.9.attn.c_attn.weight: kept 803593/998397
[prune][debug] transformer.h.9.attn.c_proj.weight: kept 615/7430
[prune][debug] transformer.h.9.ln_2.weight: kept 768/768
[prune][debug] transformer.h.9.mlp.c_fc.weight: kept 1063393/1330909
[prune][debug] transformer.h.9.mlp.c_proj.weight: kept 2540/29442
[prune][debug] transformer.h.10.ln_1.weight: kept 768/768
[prune][debug] transformer.h.10.attn.c_attn.weight: kept 802514/999007
[prune][debug] transformer.h.10.attn.c_proj.weight: kept 609/7452
[prune][debug] transformer.h.10.ln_2.weight: kept 768/768
[prune][debug] transformer.h.10.mlp.c_fc.weight: kept 1063365/1331749
[prune][debug] transformer.h.10.mlp.c_proj.weight: kept 2472/30196
[prune][debug] transformer.h.11.ln_1.weight: kept 768/768
[prune][debug] transformer.h.11.attn.c_attn.weight: kept 802337/1001304
[prune][debug] transformer.h.11.attn.c_proj.weight: kept 659/7812
[prune][debug] transformer.h.11.ln_2.weight: kept 768/768
[prune][debug] transformer.h.11.mlp.c_fc.weight: kept 1064987/1331299
[prune][debug] transformer.h.11.mlp.c_proj.weight: kept 2580/30746
[prune][debug] transformer.ln_f.weight: kept 768/768
[prune][debug] remaining unmasked after prune: 40754792/50943489

[monitor] … → ZEROED OUT
[sparsity] 40754792/124373760 non-zero → 32.77%
i8035:2153614:2153680 [0] NCCL INFO [Service thread] Connection closed by localRank 0
i8035:2153616:2153674 [2] NCCL INFO [Service thread] Connection closed by localRank 2
i8035:2153618:2153678 [3] NCCL INFO [Service thread] Connection closed by localRank 3
i8035:2153615:2153675 [1] NCCL INFO [Service thread] Connection closed by localRank 1
i8035:2153614:2153920 [0] NCCL INFO comm 0x8698d20 rank 0 nranks 4 cudaDev 0 busId b000 - Abort COMPLETE
i8035:2153618:2153921 [3] NCCL INFO comm 0x8ca9e20 rank 3 nranks 4 cudaDev 3 busId 90000 - Abort COMPLETE
i8035:2153615:2153922 [1] NCCL INFO comm 0xa612660 rank 1 nranks 4 cudaDev 1 busId 11000 - Abort COMPLETE
i8035:2153616:2153919 [2] NCCL INFO comm 0x88e8b40 rank 2 nranks 4 cudaDev 2 busId 8b000 - Abort COMPLETE
